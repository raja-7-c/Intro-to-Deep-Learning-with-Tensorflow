{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "l10c04_nlp_optimizing_the_text_generation_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "punL79CN7Ox6"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph5eir3Pf-3z"
      },
      "source": [
        "# Optimizing the Text Generation Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c04_nlp_optimizing_the_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c04_nlp_optimizing_the_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCxhW3mtLmfb"
      },
      "source": [
        "You've already done some amazing work with generating new songs, but so far we've seen some issues with repetition and a fair amount of incoherence. By using more data and further tweaking the model, you'll be able to get improved results. We'll once again use the [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics) here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHK2CYygXom"
      },
      "source": [
        "## Import TensorFlow and related functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LmLTREBf5ng"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmLTO_dpgge9"
      },
      "source": [
        "## Get the Dataset\n",
        "\n",
        "As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bf5FVHfganK",
        "outputId": "25dd5806-2b8d-4e79-c2cf-202b0601bb59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-01 05:02:42--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 172.217.2.110, 2607:f8b0:4004:836::200e\n",
            "Connecting to drive.google.com (drive.google.com)|172.217.2.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/p34bpmc55mikllt95mm5tieqt0a8jl76/1625115750000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-07-01 05:02:45--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/p34bpmc55mikllt95mm5tieqt0a8jl76/1625115750000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 172.217.13.65, 2607:f8b0:4004:808::2001\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|172.217.13.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv       [     <=>            ]  69.08M  62.6MB/s    in 1.1s    \n",
            "\n",
            "2021-07-01 05:02:46 (62.6 MB/s) - ‘/tmp/songdata.csv’ saved [72436445]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz9x-7dWihxx"
      },
      "source": [
        "## 250 Songs\n",
        "\n",
        "Now we've seen a model trained on just a small sample of songs, and how this often leads to repetition as you get further along in trying to generate new text. Let's switch to using the 250 songs instead, and see if our output improves. This will actually be nearly 10K lines of lyrics, which should be sufficient.\n",
        "\n",
        "Note that we won't use the full dataset here as it will take up quite a bit of RAM and processing time, but you're welcome to try doing so on your own later. If interested, you'll likely want to use only some of the more common words for the Tokenizer, which will help shrink processing time and memory needed (or else you'd have an output array hundreds of thousands of words long)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWbMN_19jfRT"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRmPPJegovBe"
      },
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIGedF3XjHj4",
        "outputId": "f52d0137-d99b-4ea1-cd13-d1256efa9384",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "# Read the dataset from csv - this time with 250 songs\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:250]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus, num_words=2000)\n",
        "total_words = tokenizer.num_words\n",
        "\n",
        "# There should be a lot more words now\n",
        "print(total_words)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quoDmw_FkNBA"
      },
      "source": [
        "### Create Sequences and Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkLAf3HmkPSo"
      },
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cECbqT-blMk-"
      },
      "source": [
        "### Train a (Better) Text Generation Model\n",
        "\n",
        "With more data, we'll cut off after 100 epochs to avoid keeping you here all day. You'll also want to change your runtime type to GPU if you haven't already (you'll need to re-run the above cells if you change runtimes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nHOp6uWlP_P",
        "outputId": "80d90f89-a434-46d1-a331-11824536b222",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1480/1480 [==============================] - 21s 8ms/step - loss: 5.9852 - accuracy: 0.0456\n",
            "Epoch 2/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 5.6758 - accuracy: 0.0505\n",
            "Epoch 3/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 5.4579 - accuracy: 0.0730\n",
            "Epoch 4/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 5.2382 - accuracy: 0.1041\n",
            "Epoch 5/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 5.0308 - accuracy: 0.1245\n",
            "Epoch 6/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.8505 - accuracy: 0.1438\n",
            "Epoch 7/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.6831 - accuracy: 0.1617\n",
            "Epoch 8/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.5334 - accuracy: 0.1772\n",
            "Epoch 9/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.4045 - accuracy: 0.1919\n",
            "Epoch 10/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 4.2893 - accuracy: 0.2041\n",
            "Epoch 11/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 4.1860 - accuracy: 0.2155\n",
            "Epoch 12/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 4.0963 - accuracy: 0.2237\n",
            "Epoch 13/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 4.0078 - accuracy: 0.2355\n",
            "Epoch 14/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.9326 - accuracy: 0.2462\n",
            "Epoch 15/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.8619 - accuracy: 0.2559\n",
            "Epoch 16/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.7940 - accuracy: 0.2658\n",
            "Epoch 17/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.7342 - accuracy: 0.2720\n",
            "Epoch 18/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.6777 - accuracy: 0.2796\n",
            "Epoch 19/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.6263 - accuracy: 0.2881\n",
            "Epoch 20/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.5748 - accuracy: 0.2937\n",
            "Epoch 21/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.5319 - accuracy: 0.2970\n",
            "Epoch 22/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.4873 - accuracy: 0.3049\n",
            "Epoch 23/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.4428 - accuracy: 0.3121\n",
            "Epoch 24/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.4102 - accuracy: 0.3169\n",
            "Epoch 25/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.3689 - accuracy: 0.3220\n",
            "Epoch 26/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.3362 - accuracy: 0.3273\n",
            "Epoch 27/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.3035 - accuracy: 0.3325\n",
            "Epoch 28/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.2695 - accuracy: 0.3388\n",
            "Epoch 29/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.2411 - accuracy: 0.3422\n",
            "Epoch 30/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.2098 - accuracy: 0.3460\n",
            "Epoch 31/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.1848 - accuracy: 0.3502\n",
            "Epoch 32/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.1527 - accuracy: 0.3562\n",
            "Epoch 33/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 3.1309 - accuracy: 0.3595\n",
            "Epoch 34/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.1069 - accuracy: 0.3646\n",
            "Epoch 35/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 3.0797 - accuracy: 0.3676\n",
            "Epoch 36/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.0585 - accuracy: 0.3727\n",
            "Epoch 37/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.0311 - accuracy: 0.3757\n",
            "Epoch 38/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 3.0091 - accuracy: 0.3794\n",
            "Epoch 39/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9877 - accuracy: 0.3836\n",
            "Epoch 40/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9666 - accuracy: 0.3873\n",
            "Epoch 41/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9458 - accuracy: 0.3896\n",
            "Epoch 42/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9359 - accuracy: 0.3915\n",
            "Epoch 43/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9141 - accuracy: 0.3962\n",
            "Epoch 44/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8930 - accuracy: 0.4009\n",
            "Epoch 45/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8758 - accuracy: 0.4011\n",
            "Epoch 46/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8585 - accuracy: 0.4054\n",
            "Epoch 47/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8410 - accuracy: 0.4096\n",
            "Epoch 48/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8264 - accuracy: 0.4101\n",
            "Epoch 49/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 2.8137 - accuracy: 0.4117\n",
            "Epoch 50/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7957 - accuracy: 0.4152\n",
            "Epoch 51/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 2.7838 - accuracy: 0.4161\n",
            "Epoch 52/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.7652 - accuracy: 0.4200\n",
            "Epoch 53/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.7542 - accuracy: 0.4229\n",
            "Epoch 54/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.7401 - accuracy: 0.4262\n",
            "Epoch 55/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.7232 - accuracy: 0.4274\n",
            "Epoch 56/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.7113 - accuracy: 0.4301\n",
            "Epoch 57/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.6980 - accuracy: 0.4305\n",
            "Epoch 58/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 2.6930 - accuracy: 0.4330\n",
            "Epoch 59/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.6673 - accuracy: 0.4371\n",
            "Epoch 60/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.6610 - accuracy: 0.4384\n",
            "Epoch 61/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 2.6483 - accuracy: 0.4402\n",
            "Epoch 62/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.6405 - accuracy: 0.4411\n",
            "Epoch 63/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.6267 - accuracy: 0.4458\n",
            "Epoch 64/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.6191 - accuracy: 0.4464\n",
            "Epoch 65/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.6162 - accuracy: 0.4464\n",
            "Epoch 66/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.5940 - accuracy: 0.4511\n",
            "Epoch 67/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.5815 - accuracy: 0.4538\n",
            "Epoch 68/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.5705 - accuracy: 0.4544\n",
            "Epoch 69/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.5637 - accuracy: 0.4537\n",
            "Epoch 70/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.5528 - accuracy: 0.4578\n",
            "Epoch 71/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.5423 - accuracy: 0.4592\n",
            "Epoch 72/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.5356 - accuracy: 0.4587\n",
            "Epoch 73/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.5284 - accuracy: 0.4617\n",
            "Epoch 74/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.5224 - accuracy: 0.4627\n",
            "Epoch 75/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.5088 - accuracy: 0.4658\n",
            "Epoch 76/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.4969 - accuracy: 0.4686\n",
            "Epoch 77/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.4854 - accuracy: 0.4698\n",
            "Epoch 78/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.4818 - accuracy: 0.4698\n",
            "Epoch 79/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.4712 - accuracy: 0.4719\n",
            "Epoch 80/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.4599 - accuracy: 0.4748\n",
            "Epoch 81/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.4540 - accuracy: 0.4760\n",
            "Epoch 82/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.4524 - accuracy: 0.4756\n",
            "Epoch 83/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 2.4355 - accuracy: 0.4788\n",
            "Epoch 84/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.4394 - accuracy: 0.4773\n",
            "Epoch 85/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.4220 - accuracy: 0.4798\n",
            "Epoch 86/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.4153 - accuracy: 0.4835\n",
            "Epoch 87/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 2.4108 - accuracy: 0.4817\n",
            "Epoch 88/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 2.4026 - accuracy: 0.4854\n",
            "Epoch 89/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3979 - accuracy: 0.4855\n",
            "Epoch 90/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 2.3818 - accuracy: 0.4887\n",
            "Epoch 91/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3756 - accuracy: 0.4882\n",
            "Epoch 92/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 2.3844 - accuracy: 0.4882\n",
            "Epoch 93/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.3754 - accuracy: 0.4885\n",
            "Epoch 94/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.3585 - accuracy: 0.4910\n",
            "Epoch 95/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3681 - accuracy: 0.4898\n",
            "Epoch 96/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.3444 - accuracy: 0.4943\n",
            "Epoch 97/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 2.3383 - accuracy: 0.4968\n",
            "Epoch 98/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.3389 - accuracy: 0.4959\n",
            "Epoch 99/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 2.3324 - accuracy: 0.4965\n",
            "Epoch 100/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.3393 - accuracy: 0.4941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgvIz20nlQcq"
      },
      "source": [
        "### View the Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOqmmarvlSLh",
        "outputId": "76c69eb9-0192-4101-b272-5535ef8e7f1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISLZZGlQlSxh"
      },
      "source": [
        "### Generate better lyrics!\n",
        "\n",
        "This time around, we should be able to get a more interesting output with less repetition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P96oVMk3lU7y",
        "outputId": "ecedca13-d23d-4761-8838-fef093d4f47c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "im feeling chills the devil are cold and been ground honey honey honey honey honey honey honey heh heh heh heh bale sin through somethings doll nights but but sometimes this isnt his voice everywhere would get it once before can go together all gonna have to make us grow people get along twist and songs of their finer blues darkness darkness darkness darkness darkness night darkness grind power local police war born local mirror loveland masters kin office song lights sense for ready for shape of livingstone together and of and growing god darkness dreadful house plague driving special drop figure office\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgJKV8_oRU9"
      },
      "source": [
        "### Varying the Possible Outputs\n",
        "\n",
        "In running the above, you may notice that the same seed text will generate similar outputs. This is because the code is currently always choosing the top predicted class as the next word. What if you wanted more variance in the output? \n",
        "\n",
        "Switching from `model.predict_classes` to `model.predict_proba` will get us all of the class probabilities. We can combine this with `np.random.choice` to select a given predicted output based on a probability, thereby giving a bit more randomness to our outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZe9gaJeoGVP",
        "outputId": "3b8b3a83-01f0-4840-8317-c63a84e43833",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Test the method with just the first word after the seed text\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "predicted_probs = model.predict(token_list)[0]\n",
        "predicted = np.random.choice([x for x in range(len(predicted_probs))], \n",
        "                             p=predicted_probs)\n",
        "# Running this cell multiple times should get you some variance in output\n",
        "print(predicted)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee7WKgRGrJy1",
        "outputId": "00472d76-deaf-4927-f7cc-e1c203d003ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Use this process for the full output generation\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  predicted_probs = model.predict(token_list)[0]\n",
        "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
        "                               p=predicted_probs)\n",
        "  output_word = \"\"\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "im feeling chills me to my love but i understood them again much touch when youre near me in my window to me to only oh drop you see you is lovelight away dawn rides by all here is bittersweet just going leave me no visitors tonight and reeling crack i know an explanation or know it too im not take it look need hawaii right out drop year of love awake his back ball mans side magic strong a dream woke doublecross set jive flash case we the more you try tonight i have i think that you please care for you\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}